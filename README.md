# Prompta
Prompta is a FastAPI-based distributed backend for running open-source LLMs (starting with GPT-OSS-20B) at scale. It’s designed to handle batch inference, SEO-optimized copywriting workflows, and other prompt-driven applications with speed and reliability.

⚡ FastAPI core – lightweight, async, production-ready API.

🧩 Distributed inference – scale across workers for high throughput.

📝 Content generation – optimized for structured product data → SEO copy.

🔌 Extensible design – plug in different models, prompts, or pipelines.

📦 Developer-friendly – clean project structure, Docker support, easy deployment.

Use Prompta to build your own AI-powered content engines, automation tools, or any system where prompts become production-ready outputs.
